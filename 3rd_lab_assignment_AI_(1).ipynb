{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2CYQhbxW9nP"
      },
      "source": [
        "### Μέλη Ομάδας:\n",
        "Ον/μο1:  σπυριδων αλεξανδρος διωχνος\n",
        "Αρ. Μητρώου 1:  03115727\n",
        "\n",
        "Ον/μο2:  \n",
        "Αρ. Μητρώου 2:  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp3PZliYaQ56",
        "outputId": "8b43cd93-32b3-448c-8cea-7a8bb9b90837"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heT7siZWZjQD"
      },
      "source": [
        "# Τεχνητή Νοημοσύνη: Εργαστηριακή Άσκηση 3 \n",
        "Στην άσκηση αυτή θα υλοποιηθούν διάφοροι (σχετικά απλοί) αλγόριθμοι μηχανικής μάθησης για την αυτόματη αναγνώριση μεταξύ 3 μουσικών είδών απο τα δεδομένα που προσφέρει η υπηρεσία Spotify. Συγκεκριμένα, θα δίνονται δύο σύνολα δεδομένων $$Ζ_{train}=\\{(x_1,y_1),\\dots,(x_n,y_n)\\}$$ $$Z_{test} = \\{(x_j,y_j),\\dots{,(x_k,y_k)}\\}$$ όπου κάθε $x_i\\in{\\mathbb{R}^p}$ είναι ένα διάνυσμα με τα μουσικά χαρακτηριστικά κάθε κομματιού (όπως dancability, acousticness κ.α.) και $y_i$ είναι το είδος του κομματιού - ένας ακέραιος στο $[0,2]$. Σε κάθε περίπτωση καλείστε να σχεδιάσετε έναν ταξινομητή, δηλαδή μια απεικόνιση $$f:\\mathbb{R}^p\\rightarrow{[0,2]}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvm0mywsZmit"
      },
      "source": [
        "# 1ο Μέρος: Αξιολόγηση\n",
        "Στο πρώτο μέρος της άσκησης θα υλοποιηθούν συναρτήσεις που θα χρησιμοποιηθούν για την αξιολόγηση των ταξινομητών που θα χρησιμοποιηθούν στα επόμενα μέρη.\n",
        "\n",
        "Παρακάτω σας δίνεται η κλάση Evaluate, η οποία υπολογίζει διάφορες μετρικές με τη μέθοδο get_metrics, εντοπίζει αντικείμενα που ταξινομήθηκαν λάθος και τα εμφανίζει (μέθοδος get_sample_of_wrong), και υπολογίζει τον πίνακα σύγχυσης (confusion matrix) όπου οπτικοποιούνται ανά κατηγορία οι προβλέψεις του ταξινομητή.\n",
        "\n",
        "Για το μέρος αυτό καλείστε να υλοποιήσετε στη μέθοδο my_accuracy τη μετρική accuracy, η οποία ορίζεται ως:\n",
        "$$accuracy = \\frac{\\#σωστών\\_προβλέψεων}{\\#δεδομένων}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WlTj48uFZhyJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class Evaluate:\n",
        "    def __init__(self, y_true, y_pred):\n",
        "        self.y_true = y_true\n",
        "        self.y_pred = y_pred\n",
        "\n",
        "    def my_accuracy(self):\n",
        "      y_true = self.y_true\n",
        "      y_pred = self.y_pred\n",
        "      \n",
        "      ##################\n",
        "      ## Your code below\n",
        "\n",
        "      corect_predictions=0\n",
        "      for elem in range(len(y_true)):\n",
        "        if y_true[elem]==y_pred[elem]:\n",
        "          corect_predictions+=1\n",
        "      # accuracy=  #σωστών_προβλέψεων   /   #δεδομένων\n",
        "      acc= corect_predictions/len(y_true)\n",
        "     \n",
        "      ## Your code above\n",
        "      ##################\n",
        "      return acc\n",
        "\n",
        "    def get_metrics(self):\n",
        "        precision = precision_score(self.y_true, self.y_pred, average = \"macro\")\n",
        "        recall = recall_score(self.y_true, self.y_pred, average = \"macro\")\n",
        "        f1 = f1_score(self.y_true, self.y_pred, average = \"macro\")\n",
        "        results = {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": self.my_accuracy()}\n",
        "        return results   \n",
        "    \n",
        "    def confusion_matrix(self):\n",
        "        cm = confusion_matrix(self.y_true, self.y_pred)\n",
        "        return cm \n",
        "\n",
        "    def get_evaluation_report(self):\n",
        "        metrics = self.get_metrics()\n",
        "        for m in metrics:\n",
        "            print(m + ': ' + str(metrics[m]))\n",
        "        cm = self.confusion_matrix()\n",
        "        print(\"Confusion matrix: \")\n",
        "        print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qcSvLy6ZpzB"
      },
      "source": [
        "Παράδειγμα χρήσης της κλάσης. Κανονικά στο x θα υπάρχουν τα δεδομένα από το dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S5hRZ9L1ZoNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe22e14d-5ea4-4fae-b721-7eed9c1702c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.75\n",
            "recall: 0.75\n",
            "f1: 0.75\n",
            "accuracy: 0.75\n",
            "Confusion matrix: \n",
            "[[3 1]\n",
            " [1 3]]\n"
          ]
        }
      ],
      "source": [
        "y_true = [1, 0, 1, 0, 0, 1, 1, 0]\n",
        "y_pred = [1, 0, 1, 0, 1, 1, 0, 0]\n",
        "\n",
        "eval = Evaluate(y_true, y_pred)\n",
        "eval.get_evaluation_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9Sex6aEZtt9"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "To dataset που σας δίνεται περιέχει πληθώρα μουσικών κομματιών για τα οποία έχουν καταγραφεί διάφορα χαρακτηριστικά τους, όπως επίσης και το μουσικό είδος στο οποίο ανήκουν. Στη συγκεκριμένη άσκηση θα δουλέψουμε με ένα υποσύνολο (αριθμητικών) χαρακτηριστικών, τα οποία συνεισφέρουν στον καθορισμό της μουσικής κατηγορίας κάθε κομματιού.  \n",
        "\n",
        "Τα χαρακτηριστικά τα οποία θα μελετήσουμε στην παρούσα άσκηση είναι τα \"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"speechiness\", ενώ οι κατηγορίες στις οποίες καλούμαστε να ταξινομήσουμε τα μουσικά κομμάτια είναι οι \"Electronic\", \"Rock\", και \"Rap\".  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCVa4LWpqraw"
      },
      "outputs": [],
      "source": [
        "# Σύνδεση του Google Colab με το Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Θα χρησιμοποιήσουμε τα DataFrames της βιβλιοθήκης pandas για να χειριστούμε τα δεδομένα μας. Μπορείτε να βρείτε περισσότερες πληροφορίες για τα pandas DataFrames στο αντίστοιχο [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)."
      ],
      "metadata": {
        "id": "5sKETzTHNgyk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvbVV9isZrwZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKpUJSpWqy-I"
      },
      "outputs": [],
      "source": [
        "# read data in the form of pandas DataFrame\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/data.csv\")\n",
        "\n",
        "# print the first 5 values of the DataFrame using .head() command\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What can we see here?\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "1mjeVnUCPVkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Επιλογή χαρακτηριστικών x και στόχων y.  \n",
        "\n",
        "Για λόγους απλότητας επιλέγουμε τα χαρακτηριστικά (inputs) και τις κατηγορίες-στόχους (genres). Καλείστε να διαχωρίσετε τα δεδομένα σε train/test set. Ας θεωρήσουμε το διαχωρισμό 30% - test set, 70% - train set."
      ],
      "metadata": {
        "id": "0EtEH-M9Ikac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHa_Qq0Efqxb"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "# χαρακτηριστικά\n",
        "inputs = [\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"speechiness\"]\n",
        "\n",
        "# κατηγορίες-στόχοι\n",
        "output = \"music_genre\"\n",
        "genres = [\"Electronic\", \"Rock\", \"Rap\"]\n",
        "\n",
        "# φιλτράρουμε το DataFrame ώστε να διατηρήσουμε μόνο τις 3 κατηγορίες που μας ενδιαφέρουν.\n",
        "data = data[data[output].isin(genres)]\n",
        "\n",
        "# dictionary to map genre to label id \n",
        "genres_to_id = {genre: i for i, genre in enumerate(genres)}\n",
        "\n",
        "# εδώ πρέπει να διαχωρίσετε τα δεδομένα σε train (70% των δεδομένων)/test set (30% των δεδομένων)\n",
        "# ονομάστε τις μεταβλητές ως εξής:\n",
        "# τα χαρακτηριστικά του train set: x_train\n",
        "# τις κατηγορίες-στόχους του train set: y_train\n",
        "# τα χαρακτηριστικά του test set: x_test\n",
        "# τις κατηγορίες-στόχους του test set: y_test\n",
        "x_test, y_test, x_train, y_train = [], [], [], []\n",
        "##################\n",
        "## Your code below\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "data=data.sample(frac=1)\n",
        "\n",
        "\n",
        "x_train=data.iloc[0:(math.floor(len(data)*0.7))][inputs].to_numpy()\n",
        "y_train=data.iloc[0:(math.floor(len(data)*0.7))][[output]].to_numpy()\n",
        "x_test=data.iloc[(math.floor(len(data)*0.7)):][inputs].to_numpy()\n",
        "y_test=data.iloc[(math.floor(len(data)*0.7)):][[output]].to_numpy()\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  y_train[i]=genres_to_id[y_train[i][0]]\n",
        "for i in range(len(y_test)):\n",
        "  y_test[i]=genres_to_id[y_test[i][0]]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "rock_data=data[data[output].isin([\"Rock\"])]\n",
        "electronic_data=data[data[output].isin([\"Electronic\"])]\n",
        "rap_data=data[data[output].isin([\"Rap\"])]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "rock_train=(rock_data.iloc[0:(math.floor(len(rock_data)*0.7))])\n",
        "rock_test=(rock_data.iloc[(math.floor(len(rock_data)*0.7)):])\n",
        "\n",
        "rap_train=(rap_data.iloc[0:(math.floor(len(rap_data)*0.7))])\n",
        "rap_test=(rap_data.iloc[(math.floor(len(rap_data)*0.7)):])\n",
        "\n",
        "electronic_train=(electronic_data.iloc[0:(math.floor(len(electronic_data)*0.7))])\n",
        "electronic_test=(electronic_data.iloc[(math.floor(len(electronic_data)*0.7)):])\n",
        "\n",
        "\n",
        "test = pd.concat([rock_test, rap_test, electronic_test])\n",
        "train = pd.concat([rock_train, rap_train, electronic_train])\n",
        "\n",
        "\n",
        "x_test=test[inputs].sort_index().to_numpy()\n",
        "y_test2=test[output].sort_index().to_numpy()\n",
        "\n",
        "x_train=train[inputs].sort_index().to_numpy()\n",
        "y_train2=train[output].sort_index().to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "#τεχτ το number\n",
        "y_test=np.zeros(len(y_test2))\n",
        "for elem in range(len(y_test2)):\n",
        "  if y_test2[elem]=='Electronic':\n",
        "    y_test[elem]=0  \n",
        "  if y_test2[elem]=='Rock':\n",
        "    y_test[elem]=1\n",
        "  if y_test2[elem]=='Rap':\n",
        "    y_test[elem]=2\n",
        "y_test\n",
        "\n",
        "\n",
        "y_train=np.zeros(len(y_train2))\n",
        "for elem in range(len(y_train2)):\n",
        "  if y_train2[elem]=='Electronic':\n",
        "    y_train[elem]=0  \n",
        "  if y_train2[elem]=='Rock':\n",
        "    y_train[elem]=1\n",
        "  if y_train2[elem]=='Rap':\n",
        "    y_train[elem]=2\n",
        "\n",
        "\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "\"\"\"\"\n",
        "x_train = x_train.tolist()\n",
        "x_test = x_test.tolist()\n",
        "\n",
        "\n",
        "y_train = y_train.tolist()\n",
        "y_test = y_test.tolist()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "## Your code above\n",
        "##################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Μορφή των δεδομένων  \n",
        "\n",
        "Βεβαιωθείτε ότι τα δεδομένα σας έχουν τη σωστή μορφή εκτυπώνοντας τον αριθμό γραμμών και στηλών για τα x_test, y_test, x_train, y_train."
      ],
      "metadata": {
        "id": "hhte3iixLg8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhDzmllUZvyp"
      },
      "outputs": [],
      "source": [
        "# Shape of x_test, y_test, x_train, y_train\n",
        "\n",
        "##################\n",
        "## Your code below\n",
        "print(len(x_test),len(x_test[0]))\n",
        "print(len(x_train),len(x_train[0]))\n",
        "print(len(y_test),len(y_train))\n",
        "\n",
        "\n",
        "## Your code above\n",
        "##################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Αναφορικά με τις τιμές των χαρακτηριστικών, είναι σημαντικό να γνωρίζουμε το εύρος τους, δηλαδή τη μέγιστη και την ελάχιστη τιμή που λαμβάνει το κάθε χαρακτηριστικό. Εξερευνήστε το εύρος του κάθε χαρακτηριστικού στα train και test set. "
      ],
      "metadata": {
        "id": "QAQ3qN1NMVpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Range of x_train, x_test columns\n",
        "\n",
        "##################\n",
        "## Your code below\n",
        "\n",
        "a1=test[inputs].sort_index()\n",
        "a2=test[[\"music_genre\"]].sort_index()\n",
        "\n",
        "a3=train[inputs].sort_index()\n",
        "a4=train[[\"music_genre\"]].sort_index()\n",
        "\n",
        "for elem in [a1,a2,a3,a4]:\n",
        "  print(elem.describe())\n",
        "\n",
        "\n",
        "## Your code above\n",
        "##################"
      ],
      "metadata": {
        "id": "twobPa_DMxI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Από την παραπάνω ανάλυση προκύπτουν κάποια ερωτήματα σημαντικά για τα επόμενα βήματα:\n",
        "- Έχουν τα χαρακτηριστικά μας περίπου το ίδιο εύρος;\n",
        "ναι\n",
        "\n",
        "- Σε πολλές εφαρμογές είναι σημαντικό τα χαρακτηριστικά να βρίσκονται στο εύρος [0, 1]. Ισχύει αυτό στην περίπτωσή μας; \n",
        "ναι"
      ],
      "metadata": {
        "id": "jZH_VbsMM_TM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYMke4uRZ8Ae"
      },
      "source": [
        "# 2o Μέρος: Υλοποίηση KNN\n",
        "Στο δεύτερο μέρος της άσκησης θα υλοποιήσετε τον αλγόριθμο KNN για ταξινόμηση. Υπενθυμίζεται από τις διαφάνειες το πλάνο σχεδιασμού για τον ταξινομητή k κοντινότερων γειτόνων:\n",
        "- Αποθηκεύουμε όλα τα δεδομένα ($Z_{train}$) στη μνήμη\n",
        "  - Τα δεδομένα μπορούν αποθηκευτούν σε έναν πίνακα $n\\times{p}$ με χρήση του numpy\n",
        "- Συγκρίνουμε την είσοδο με τα δεδομένα και βρίσκουμε τα k κοντινότερα ($k<n$) με βάση κάποια απόσταση.\n",
        "  - Όταν μας δίνεται ένα \"φρέσκο\" δείγμα ως διάνυσμα από χαρακτηριστικά $x_i$ χρειαζόμαστε μια συνάρτηση που να υπολογίζει την απόσταση $d(x_i,x_j)$, όπου $x_j$ είναι το διάνυσμα που αντιστοιχεί στα χαρακτηριστικά ενός δείγματος από τα δεδομένα εκπαίδευσης. Θα πειραματιστείτε με την ευκλείδια απόσταση και την απόσταση συνημιτόνου. Στη συνέχεια ταξινομούνται τα δεδομένα εκπαίδευσης ως προς την απόστασή τους από το $x_i$ και επιλέγονται τα $k$ κοντινότερα\n",
        "- Δίνουμε στην έξοδο την κλάση στην οποία ανήκει η πλειοψηφία των k κοντινότερων δεδομένων.\n",
        "\n",
        "Αφού κατασκευαστεί ο ταξινομητής θα αξιολογήσετε την επίδοσή του στα 100 πρώτα δείγματα του $Z_{test}$ για κάποιες τιμές του k που θα επιλέξετε εσείς, ξεκινώντας από $k=1$.\n",
        "\n",
        "Στην πράξη πολύ σπάνια θα χρειαστεί να υλοποιήσετε έναν αλγόριθμο μηχανικής μάθησης από το μηδέν, αφού υπάρχουν έτοιμες υλοποιήσεις, π.χ. σε πακέτα της python, οι οποίες είναι βελτιστοποιημένες και εύχρηστες. Το τελευταίο ζητούμενο  στο 2ο μέρος είναι να επαναλάβετε το παραπάνω πείραμα με την έτοιμη υλοποίηση του KNN που παρέχει η βιβλιοθήκη sklearn. Καλείστε να συγκρίνετε τα αποτελέσματα και τους χρόνους εκτέλεσης.\n",
        "\n",
        " Σας δίνεται η κλάση KNN η οποία αρχικοποιείται με ένα σύνολο από δεδομένα x, ετικέτες y και το k για τον αλγόριθμο. Καλείστε να συμπληρώσετε τον κώδικα που λείπει στις μεθόδους distance, get_knn, και classify.\n",
        "\n",
        "Η απόσταση συνημιτόνου μεταξύ δύο διανυσμάτων u,v ορίζεται ως: $$d(u,v)= 1 - \\frac{u\\cdot{v}}{||u||_2||v||_2}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMPfT1jTZ51F"
      },
      "outputs": [],
      "source": [
        "from numpy import linalg\n",
        "from scipy.spatial import distance as dst\n",
        "\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, x, y, k, distance = \"euclidean\"):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.k = k\n",
        "        self.distance = distance\n",
        "        \n",
        "    ## Compute the distance between the two vectors (2 rows of the DataFrame)\n",
        "    # hint: use np.linalg.norm for eucledian\n",
        "    # hint: use equation given above for cosine\n",
        "    def get_distance(self, row1, row2):\n",
        "      if self.distance=='euclidian':\n",
        "        ##################\n",
        "        ## Your code below\n",
        "        dist = np.linalg.norm(row1-row2)\n",
        "        \"\"\"\n",
        "        #np.linalg.norm δεν δουλεψε οποτε την έκανα μονος μου\n",
        "        dist=0\n",
        "        for i in range(len(row1)):\n",
        "          dist=dist+(row1[i]-row2[i])**2\n",
        "        dist=math.sqrt(dist)\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        ## Your code above\n",
        "        ##################\n",
        "      else:\n",
        "        ##################\n",
        "        ## Your code below\n",
        "        dist = dst.cosine(row1, row2)\n",
        "\n",
        "        \"\"\"\n",
        "       dist =0\n",
        "        temp1=0\n",
        "        temp2=0\n",
        "        \n",
        "        for i in range(len(row1)):\n",
        "          temp1=temp1+(row1[i])**2\n",
        "          temp2=temp2+(row2[i])**2\n",
        "        temp1=math.sqrt(temp1)\n",
        "        temp2=math.sqrt(temp2)  \n",
        "\n",
        "        for i in range(len(row1)):\n",
        "          dist=dist+(row1[i]*row2[i])\n",
        "\n",
        "        dist=dist/(temp1*temp2)\n",
        "        dist=1-dist\n",
        "        \"\"\"\n",
        "      \n",
        "      \n",
        "        ## Your code above\n",
        "        ##################\n",
        "        \n",
        "\n",
        "      return dist\n",
        "\n",
        "    ## Given a DataFrame row as a vector, returns indexes of k nearest neighbors\n",
        "    def get_knn(self, row):\n",
        "      distances = list()\n",
        "      x = self.x\n",
        "      k = self.k\n",
        "      \n",
        "      ##################\n",
        "      ## Your code below - populate the distances list\n",
        "      # hint: you can use a for loop\n",
        "      for my_row in self.x:\n",
        "        distances.append(self.get_distance(row, my_row))\n",
        "      ## Your code above\n",
        "      ##################\n",
        "\n",
        "      # Sort distances, and return the indexes of k first elements\n",
        "      ans_indexes = np.argsort(distances)[:k]\n",
        "      return ans_indexes\n",
        "\n",
        "    ## Given a DataFrame row as a vector, classify it according to KNN\n",
        "    # hint: we have a list of k labels and want to return the most common one\n",
        "    def classify(self, row):\n",
        "      y = self.y\n",
        "      nn_labels = [y[i] for i in self.get_knn(row)]\n",
        "      ##################\n",
        "      ## Your code below\n",
        "      prediction = max(set(nn_labels), key = nn_labels.count)\n",
        "      ## Your code above\n",
        "      ###################\n",
        "      return prediction\n",
        "\n",
        "\n",
        "knn = KNN(x_train, y_train, k=5, distance='euclidian')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8-o5tn3aH0-"
      },
      "source": [
        "Τώρα που είναι έτοιμος ο ταξινομητής ας δούμε τι προβλέπει σε μεμονωμένα δείγματα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCiEi1UUaLzE"
      },
      "source": [
        "## Αξιολόγηση του KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKw0oa1jaJei"
      },
      "outputs": [],
      "source": [
        "\n",
        "preds = [knn.classify(x_test[i]) for i in range(100)]\n",
        "\n",
        "labels = [y_test[i] for i in range(100)]\n",
        "print(preds)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNVygiKCaNag"
      },
      "outputs": [],
      "source": [
        "eval = Evaluate(labels, preds)\n",
        "eval.get_evaluation_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7LP247HaU6m"
      },
      "source": [
        "## Έτοιμος ΚΝΝ classifier\n",
        "\n",
        "Όπως και με τους περισσότερους αλγορίθμους μηχανικής μάθησης, υπάρχουν έτοιμες βελτιστοποιημένες υλοποιήσεις. Παρακάτω δείχνουμε ένα παράδειγμα χρήσης του ταξινομητή ΚΝΝ που παρέχει η βιβλιοθήκη sklearn ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os0WCL-QaOnr"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "k = 5\n",
        "knc = KNeighborsClassifier(n_neighbors = k)\n",
        "knc.fit(x_train, y_train)\n",
        "y_pred = knc.predict(x_test[:100])\n",
        "\n",
        "eval = Evaluate(y_test[:100], y_pred)\n",
        "eval.get_evaluation_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcUBX2XMaZUd"
      },
      "source": [
        "## Σύγκριση υλοποιήσεων\n",
        "\n",
        "Στα παρακάτω κελιά πειραματιστείτε με τις δύο υλοποιήσεις (τη δική σας και την έτοιμη). Βεβαιωθείτε πως προκύπτουν τα ίδια αποτελέσματα για διάφορες τιμές του k (για ευκλείδια απόσταση) και μετρήστε τους χρόνους εκτέλεσης."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOmj0ryqW9nY"
      },
      "source": [
        "Για τους χρόνους εκτέλεσης για k = 5 τρέχουμε τα 3 παρακάτω κελιά:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yz_Y_cpaWor"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "knn = KNN(x_train, y_train, k = 5, distance = 'euclidean')\n",
        "preds = [knn.classify(x_test[i]) for i in range(100)]\n",
        "Evaluate(y_test[:100], preds).get_evaluation_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "683epgE6W9nY"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "knn = KNN(x_train, y_train, k = 5, distance = 'cosine')\n",
        "preds = [knn.classify(x_test[i]) for i in range(5)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77s6o3ZkabCY"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "knc = KNeighborsClassifier(n_neighbors = 5)\n",
        "knc.fit(x_train, y_train)\n",
        "y_pred = knc.predict(x_test[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6rb5SKKW9nY"
      },
      "source": [
        "Για τους χρόνους εκτέλεσης για k = 50 τρέχουμε τα 3 παρακάτω κελιά:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvDbD3u7W9nZ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "knn = KNN(x_train, y_train, k = 50, distance = 'euclidean')\n",
        "preds = [knn.classify(x_test[i]) for i in range(100)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YpuwMD0W9nZ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "knn = KNN(x_train, y_train, k = 50, distance = 'cosine')\n",
        "preds = [knn.classify(x_test[i]) for i in range(5)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h4GOLcNW9nZ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "knc = KNeighborsClassifier(n_neighbors = 50)\n",
        "knc.fit(x_train, y_train)\n",
        "y_pred = knc.predict(x_test[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc9ySKoRaek-"
      },
      "source": [
        "## Σχολιασμός\n",
        "<εδώ γράφετε τυχόν σχόλια και παρατηρήσεις που έχετε στο δευτερο μέρος: παραδοχές, επίδοση, χρόνος εκτέλεσης, επίδραση παραμέτρου k κλπ >\n",
        "\n",
        "\n",
        "παρατηρήσαμε ότι έχουμε το ίδιο αποτέλεσμα με την έτοιμη υλοποίηση, το οποίο το περιμέναμε καθώς δεν υπάρχει τυχερότατα σε αυτό το μέρος\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe17UwwLag5Y"
      },
      "source": [
        "# 3ο Μέρος: Naive Bayes\n",
        "Στο τρίτο μέρος της άσκησης θα υλοποιήσετε τον αλγόριθμο Naive Bayes. Ας θυμηθούμε από τις διαφάνειες:\n",
        "\n",
        "**Υποθέσεις:**\n",
        "- Τα χαρακτηριστικά είναι boolean αντί για συνεχή, δηλαδή παίρνουν δύο τιμές 0 ή 1. Συνεπώς, χρειάζεται να τροποποιήσουμε τα χαρακτηριστικά του dataset μας.\n",
        "  - Για το συγκεκριμένο πρόβλημα μπορούμε να 'σπάσουμε' τις τιμές κάθε χαρακτηριστικού σε N διαφορετικά bins. Για παράδειγμα, για ένα χαρακτηριστικό που οι τιμές του κυμαίνονται στο [0, 1], για Ν=5, θα έχουμε τα ακόλουθα bins: [0, 0.2), [0.2, 0.4), [0.4, 0.6), [0.6, 0.8), [0.8, 1]. (Γι αυτό το λόγο στα προηγούμενα βήματα αναφέραμε ότι είναι σημαντικό να έχουμε τα χαρακτηριστικά μας στο [0, 1]!)\n",
        "  \n",
        "- Η πιθανότητα ένα στοιχείο με χαρακτηριστικά x να ανήκει στην κλάση i δίνεται από τον τύπο:\n",
        "$$p(i|x)=\\frac{p(i)\\cdot{\\prod_{k=1}^p}p(x^{(k)}|i)}{\\sum_{j=1}^pp(x^{(k)}|j)}$$\n",
        "- Για να ταξινομήσουμε ένα διάνυσμα χαρακτηριστικών x σε μια κλάση i επιλέγουμε την κλάση που μεγιστοποιεί την παραπάνω πιθανότητα\n",
        "  - Μπορούμε για τη σύγκριση να αγνοήσουμε τον παρονομαστή, αφού για όλες τις κλάσεις θα είναι ίδιος"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNbBhsg2ach8"
      },
      "outputs": [],
      "source": [
        "# κάνουμε κάθε μεταβλήτη του συνόλου εκπαίδευσης διακρίτη σε σε διαστήματα \n",
        "\n",
        "def discretize(x, num_of_classes = 5):  \n",
        "    x_r = []\n",
        "    for row in x:\n",
        "        discrete = []\n",
        "        for i, feature in enumerate(row):\n",
        "            discrete_feature = [0] * num_of_classes\n",
        "            for j, v in enumerate(np.linspace(0, 1, num_of_classes + 1)):\n",
        "                if float(feature) < v:\n",
        "                    break\n",
        "            discrete_feature[j-1] = 1\n",
        "            discrete += discrete_feature\n",
        "        x_r.append(discrete)\n",
        "    return np.array(x_r)\n",
        "\n",
        "x_train_r = discretize(x_train)\n",
        "x_test_r = discretize(x_test)\n",
        "len(x_test_r[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFORd6XJakZl"
      },
      "source": [
        "Παρακάτω σας δίνεται η κλάση NaiveBayes που υλοποιεί τον αλγόριθμο. Καλείστε αρχικά να υπολογίσετε την πιθανότητα $p(x^{(k)}|i)$ για διάνυσμα χαρακτηριστκών $x$ και κατηγορία $i$ στη μέθοδο compute_probabilities. Στη συνέχεια θα υπολογίσετε την πιθανότητα $p(i|x)$ στη μέθοδο predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufKo5f5yaiqH"
      },
      "outputs": [],
      "source": [
        "class NaiveBayes:\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "\n",
        "        ## pC is a vector with the probability of each class\n",
        "        self.pC = np.zeros((len(genres),))\n",
        "        ## pxC is an array with all probabilities p(xi|C)\n",
        "        self.pxC = np.zeros((x.shape[-1], len(genres)))\n",
        "        ## Compute the probabilities\n",
        "        self.compute_probabilities()\n",
        "\n",
        "    def compute_probabilities(self):\n",
        "        ## Compute p(C) for each class\n",
        "        for label in self.y: \n",
        "          self.pC[label] += 1\n",
        "        self.pC = self.pC / self.y.shape[0]\n",
        "\n",
        "        # self.pc ===== prob of rock or prob of rap or prob of elec\n",
        "\n",
        "\n",
        "        ## Compute p(xi|C) for each feature xi and class C  \n",
        "        # hint: you can use one or more for loops\n",
        "        ###################\n",
        "        ## Your code below\n",
        "\n",
        "        total_instances=[0,0,0]\n",
        "        for j in range(len(self.x)):\n",
        "          for i in range(len(self.x[0])):\n",
        "\n",
        "            if self.y[j]==0:\n",
        "              self.pxC[i][0]+=self.x[j][i]\n",
        "              total_instances[0]+=1\n",
        "\n",
        "            if self.y[j]==1:\n",
        "              self.pxC[i][1]+=self.x[j][i]\n",
        "              total_instances[1]+=1\n",
        "\n",
        "            if self.y[j]==2:\n",
        "              self.pxC[i][2]+=self.x[j][i]\n",
        "              total_instances[2]+=1\n",
        "\n",
        "        \n",
        "        for j in range(len(self.pxC)):\n",
        "          for i in range(len(self.pxC[0])):\n",
        "           \n",
        "            self.pxC[j][i]/=total_instances[i]\n",
        "\n",
        "        ## Your code above\n",
        "        ##################\n",
        "\n",
        "    def predict(self, x):\n",
        "        ## ~Probability of x belonging to each class\n",
        "        ## (not actucal probability since we ignore denominator)\n",
        "        pcX = np.ones((len(genres),))\n",
        "        xsize = self.x.shape[-1]\n",
        "        for i in range(len(genres)): ##i ===rock\n",
        "          # hint: We have probabilities p({x_j=1}|i) in self.pxC\n",
        "          # We also need p({x_j=0}|i) for computing p(x|i)\n",
        "          #################\n",
        "          ## Your code \n",
        "          #for j in range(len(self.x)):\n",
        "          res =self.pC[i]\n",
        "          for itel in range(len(x)):\n",
        "            if x[itel] ==1:\n",
        "              res*=self.pxC[itel][i]\n",
        "              \n",
        "          pcX[i]=res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          ## Your code above\n",
        "          ##################\n",
        "        return np.argmax(pcX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO9h_Q8bbAgF"
      },
      "source": [
        "## Αξιολόγηση του Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PzuaP48amDv"
      },
      "outputs": [],
      "source": [
        "\n",
        "nb = NaiveBayes(x_train_r, y_train)\n",
        "preds = [nb.predict(i) for i in x_test_r[:100]]\n",
        "eval = Evaluate(y_test[:100], preds)\n",
        "eval.get_evaluation_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMUHg-dubFa2"
      },
      "source": [
        "## Έτοιμος Naive Bayes\n",
        "\n",
        "Όπως με τους περισσότερους αλγορίθμους μηχανικής μάθησης, υπάρχουν έτοιμες βελτιστοποιημένες υλοποιήσεις για τον Naive Bayes. Παρακάτω ο Gaussian Naive Bayes από το Sklearn. Σε αντίθεση με τη δική μας υλοποίηση, ο συγκεκριμένος δουλεύει και με συνεχή δεδομένα, αφού πρώτα κάνει την υπόθεση πως κάθε χαρακτηριστικό ακολουθεί κανονική κατανομή ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNir3SOIW9nb"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "y_pred = gnb.fit(x_train, y_train).predict(x_test[:100])\n",
        "\n",
        "eval = Evaluate(y_test[:100], y_pred)\n",
        "eval.get_evaluation_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaecLreybI-3"
      },
      "source": [
        "## Σύγκριση υλοποιήσεων\n",
        "\n",
        "Όμοια με πριν θα συγκρίνετε τα αποτελέσματα και τους χρόνους εκτέλεσης για τις δύο υλοποιήσεις. Σχολιάστε την επίδοση σε κάθε περίπτωση. Ποιες από τις παραδοχές που κάναμε δεν ισχύουν;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz-k1DL-bG9v"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "nb = NaiveBayes(x_train_r,y_train)\n",
        "preds = [ nb.predict(i) for i in x_test_r[:100]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neUU0A-AW9nc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "gnb = GaussianNB()\n",
        "y_pred = gnb.fit(x_train, y_train).predict(x_test[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAmP4BrCbOB9"
      },
      "source": [
        "## Σχολιασμός\n",
        "\n",
        "<εδώ γράφετε τυχόν σχόλια και παρατηρήσεις που έχετε στο τρίτο μέρος: παραδοχές, επίδοση, χρόνος εκτέλεσης, επίδραση bining/υπόθεσης κατανομής κλπ. >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B3FYDfnW9nd"
      },
      "source": [
        "# 4ο Μέρος: Multi-Layer Perceptron \n",
        "\n",
        "Στο τέταρτο μέρος της άσκησης θα κατασκευάσετε ένα πολυεπίπεδο νευρωνικό δίκτυο. Ο ταξινομητής αυτός θα εκπαιδευτεί στο να ταξινομεί τα δείγματα των μουσικών κομματιών σε μια από τις 3 διαφορετικές κλάσεις που επιλέχθηκαν (Electronic, Rock, Rap). Αρχικά, θα υλοποιήσετε το μοντέλο αυτό χρησιμοποιώντας αποκλειστικά την βιβλιοθήκη numpy ενώ στην συνέχεια θα χρησιμοποιήσετε μια έτοιμη κλάση για την κατασκευή του ίδιου μοντέλου. \n",
        "\n",
        "Ας θυμηθούμε από τις διαφάνειες: \n",
        "\n",
        "Κάθε MLP αποτελείται από επίπεδα όπου το κάθε ένα από αυτά χωρίζεται στα παρακάτω μέρη: \n",
        "\n",
        "$$ z(x) = w^Τx + b $$ \n",
        "$$ f(x) = a(z(x))$$ \n",
        "\n",
        "όπου $w$, $b$ είναι τα βάρη του επιπέδου.  Η έξοδος z(x) είναι η απόκριση κάθε νευρώνα πριν την συνάρτηση ενεργοποίησης ενώ η f(x) μετά.  Κάθε επίπεδο συνδέεται με ένα επόμενο του οποίου η είσοδός του αποτελεί την έξοδο (με την συνάρτηση ενεργοποίησης) του προηγούμενου. \n",
        "\n",
        "Στο μέρος αυτό καλείστε να συμπληρώσετε ορισμένα σημεία κώδικα ώστε να επιτυγχάνεται αυτή η λειτουργικότητα. Στην συνέχεια θα υλοποιήσετε το ίδιο ακριβώς μοντέλο χρησιμοποιώντας όμως μια έτοιμη βιβλιοθήκη και θα συγκρίνετε τα αποτελέσματά τους (χρόνο, σκορ κ.α.). \n",
        "\n",
        "Σε αυτό το σημείο της άσκησης θα επιλύσετε το παραπάνω πρόβλημα κατασκευάζοντας ένα πολυεπίπεδο νευρωνικό δίκτυο. Αρχικά θα υλοποιήσετε το νευρωνικό χωρίς να χρησιμοποιήσετε κάποια έτοιμη κλάση κάποιας βιβλιοθήκης (όπως scikit-learn, keras), ενώ στην συνέχεια θα κατασκευάσετε το ίδιο σύστημα με την χρήση της βιβλιοθήκης scikit-learn. \n",
        "\n",
        "Στο παρακάτω κελί κώδικα σάς δίνεται η βασική δομή του επιπέδου ενός πολυεπίπεδου νευρωνικού δικτύου. Η παρακάτω κλάση δεν υλοποιεί κάποιο πραγματικό επίπεδο (όπως Dense) αλλά αυτή χρησιμοποιείται για την παρουσίαση των λειτουργιών κάθε επιπέδου.\n",
        "\n",
        "Ουσιαστικά κάθε επίπεδο ενός νευρωνικού δικτύου πρέπει να είναι σε θέση να κάνει: \n",
        "\n",
        "\n",
        "1.   Για μια είσοδο να υπολογίζει την έξοδο κάθε νευρώνα. Αυτό επιτυγχάνεται μέσω της μεθόδου forward η όποια δέχεται ως όρισμα μια είσοδο  και επιστρέφει έναν πίνακα με τις εξόδους κάθε νευρώνα του επιπέδου. \n",
        "\n",
        "2.   Να υπολογίζει τις μεταβολές οι όποιες πρέπει να γίνουν στα βάρη κάθε επιπέδου, ανάλογα με το πόσο καλά-κοντινά ήταν τα αποτελέσματα του επιπέδου στα πραγματικά. Η λειτουργία αυτή θα μας βοηθήσει στην ανανέωση των βαρών του δικτύου και συνεπώς στη σωστή εκπαίδευσή του. Η λειτουργικότητα αυτή επιτυγχάνεται μέσω της μεθόδου backward. \n",
        "\n",
        "  \n",
        "\n",
        "Η λειτουργικότητα, συνεπώς, κάθε επιπέδου καθορίζεται από την συνάρτηση που υλοποιείται στην μέθοδο forward. Ένα instance της παρακάτω κλάσης, συνεπώς, επιστρέφει ως έξοδο την είσοδο κάθε νευρώνα (ταυτοτική συνάρτηση) όποτε δεν προσφέρει κάποια υψηλή λειτουργικότητα. Στην παρακάτω κλάση δεν έχετε να προσθέσετε κάτι, απλά να μελετήσετε και να καταλάβετε την δομή που πρέπει να έχει ένα επίπεδο. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgx1VIMmbMQP"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        \"\"\"Here we can initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n",
        "        # A dummy layer does nothing\n",
        "        pass\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Takes input data of shape [batch, input_units], returns output data [batch, output_units]\n",
        "        \"\"\"\n",
        "        # A dummy layer just returns whatever it gets as input.\n",
        "        return input\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        # The gradient of a dummy layer is precisely grad_output, but we'll write it more explicitly\n",
        "        num_units = input.shape[1]\n",
        "        \n",
        "        d_layer_d_input = np.eye(num_units)\n",
        "        \n",
        "        return np.dot(grad_output, d_layer_d_input) # chain rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1iQCroAbV-F"
      },
      "source": [
        "Στο σημείο αυτό αξίζει να αναφερθεί ότι για την σωστή εκπαίδευση του δικτύου (σε πρακτικό επίπεδο) πρέπει να διαχωριστεί η έξοδος κάθε νευρώνα πριν και μετά την συνάρτηση ενεργοποίησης. Έτσι η παραπάνω μέθοδος forward της κλάσης layer πρέπει να υπολογίζει την έξοδο του επιπέδου χωρίς την συνάρτηση ενεργοποίησης και κάποια άλλη κλάση να υπολογίζει το αποτέλεσμα με αυτή.  \n",
        "\n",
        "  \n",
        "\n",
        "Έκτος όμως από την εκπαίδευση του δικτύου, ο διαχωρισμός αυτός μας βοηθά σημαντικά και κατά την φάση σχεδιασμού της  αρχιτεκτονικής μιας και μας δίνει την δυνατότητα να αλλάζουμε την συνάρτηση ενεργοποίησης χωρίς κάθε φόρα να πρέπει να αλλάξουμε ολόκληρη την κλάση layer. Για τους παραπάνω λόγους θα χειριζόμαστε την συνάρτηση ενεργοποίησης σαν ένα ξεχωριστό επίπεδο με τις δικές της μεθόδους: forward, backward.  \n",
        "\n",
        "  \n",
        "\n",
        "Παρακάτω παρουσιάζεται η κλάση η όποια υλοποιεί την λειτουργικότητα της συνάρτησης ενεργοποίησης [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)).  \n",
        "\n",
        "  \n",
        "\n",
        "Με την ίδια λογική μπορούμε να υλοποιήσουμε οποιαδήποτε άλλη συνάρτηση ενεργοποίησης θέλουμε π.χ. sigmoid, tanh κ.ο.κ. και επιπλέον μπορούμε να τις εναλλάσσουμε μεταξύ επιπέδων χωρίς δυσκολία. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P33228VbYIf"
      },
      "outputs": [],
      "source": [
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"Apply elementwise ReLU to [batch, input_units] matrix\"\"\"\n",
        "        relu_forward = np.maximum(0, input)\n",
        "        return relu_forward\n",
        "    \n",
        "    def backward(self, input, grad_output):\n",
        "        \"\"\"Compute gradient of loss w.r.t. ReLU input\"\"\"\n",
        "        relu_grad = input > 0\n",
        "        return grad_output*relu_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrrub_76ba19"
      },
      "source": [
        "Η κλάση Dense υλοποιεί ένα επίπεδο dense όπου η έξοδος κάθε νευρώνα (χωρίς τη  συνάρτηση ενεργοποίησης) υπολογίζεται από την παρακάτω εξίσωση: \n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "$$ z(x) = w^Τx + b $$ \n",
        "\n",
        "  \n",
        "\n",
        "όπου $w$, $b$ είναι τα βάρη του επιπέδου.   \n",
        "\n",
        "  \n",
        "\n",
        "Συνεπώς το δίκτυο είναι απαραίτητο να διατηρεί τους δυο πίνακες με τα βάρη οι οποίοι στην μέθοδο forward θα χρησιμοποιούνται για τον υπολογισμό της εξόδου και θα ανανεώνονται από την μέθοδο backward. Οι πίνακες αυτοί δημιουργούνται κατά την κατασκευή κάθε στιγμιότυπου και αρχικοποιούνται, ο πρώτος τυχαία και ο δεύτερος με μηδενικά.  Στο σημείο αυτό καλείστε να συμπληρώσετε την μέθοδο forward με κατάλληλο τρόπο ώστε να επιτυγχάνεται η επιθυμητή λειτουργικότητα. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEnuIuOHbZge"
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "    def __init__(self, input_units, output_units, learning_rate = 0.1):\n",
        "        self.input_units = input_units\n",
        "        self.output_units = output_units\n",
        "        \n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.random.normal(loc = 0.0, \n",
        "                                        scale = np.sqrt(2 / (input_units + output_units)), \n",
        "                                        size = (input_units, output_units))\n",
        "        self.biases = np.zeros(output_units)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Perform an affine transformation:\n",
        "        f(x) = <W*x> + b\n",
        "        \n",
        "        input shape: [number of inputs, input units]\n",
        "        output shape: [number of inputs, output units]\n",
        "        \"\"\"\n",
        "        ###################\n",
        "        ## Your code below\n",
        "        ## hint: numpy.dot\n",
        "\n",
        "\n",
        "        \n",
        "        ## Your code above\n",
        "        ##################\n",
        "        return output\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        # compute d f / d x = d f / d dense * d dense / d x\n",
        "        # where d dense/ d x = weights transposed\n",
        "        grad_input = np.dot(grad_output, self.weights.T)\n",
        "\n",
        "        # compute gradient w.r.t. weights and biases\n",
        "        grad_weights = np.dot(input.T, grad_output)\n",
        "        grad_biases = grad_output.mean(axis = 0) * input.shape[0]\n",
        "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
        "\n",
        "        # Here we perform a stochastic gradient descent step. \n",
        "        self.weights = self.weights - self.learning_rate * grad_weights\n",
        "        self.biases = self.biases - self.learning_rate * grad_biases\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml2jvLeybeRe"
      },
      "source": [
        "Οι παρακάτω συναρτήσεις χρησιμοποιούνται για να μπορεί το δίκτυο να ελέγχει πόσο κοντά βρίσκονται τα αποτελέσματά του στα πραγματικά (Loss function). Όπως είναι λογικό υπάρχουν διαφορετικές τέτοιες συναρτήσεις ανάλογα το πρόβλημα που καλείται να λύσει το δίκτυο. Η παρακάτω συνάρτηση ονομάζεται [softmax](https://en.wikipedia.org/wiki/Softmax_function) και χρησιμοποιείται κατά κύριο λόγο σε προβλήματα ταξινόμησης όπως το συγκεκριμένο. Η softmax δέχεται σαν είσοδο τις ενεργοποιήσεις του τελευταίου επιπέδου και επιστρέφει μια κατανομή πιθανοτήτων για κάθε μια από τις κλάσεις εξόδου (π.χ. κλάση 0 έχει πιθανότητα 0.001,  η κλάση 1 έχει 0.9 κ.ο.κ.).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qT7nl_1Gbc0B"
      },
      "outputs": [],
      "source": [
        "def softmax_crossentropy_with_logits(logits, reference_answers):\n",
        "    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
        "    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
        "    return xentropy\n",
        "\n",
        "def grad_softmax_crossentropy_with_logits(logits, reference_answers):\n",
        "    ones_for_answers = np.zeros_like(logits)\n",
        "    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
        "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
        "    return (- ones_for_answers + softmax) / logits.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XnSJjxYbhdX"
      },
      "source": [
        "Έχοντας υλοποιήσει τις κλάσεις Dense και ReLU μπορούμε πλέον να κατασκευάσουμε μια κλάση η όποια θα ορίζει ένα πολυεπίπεδο νευρωνικό δίκτυο (MLP). Το δίκτυο αυτό ουσιαστικά αποτελείται από μια ακολουθία Dense επιπέδων όπου το κάθε ένα (εκτός του τελευταίου) ακολουθείται από μια μη-γραμμική συνάρτηση ενεργοποίησης (ReLU). Όμοια με πριν, η κλάση αυτή πρέπει να περιέχει μια μέθοδο forward η όποια θα δέχεται μια είσοδο (εδώ μια εικόνα flatten) και θα επιστρέφει μια έξοδο (εδώ μια κατανομή 3 πιθανοτήτων). Παράλληλα πρέπει να περιέχει και μια μέθοδο fit, η όποια θα εκπαιδεύει το δίκτυο δεδομένου ενός τέτοιου συνόλου (εδώ του x_train). Στο σημείο αυτό χρησιμοποιούνται οι μέθοδοι backward που έχουν οριστεί για κάθε ένα επίπεδο (δεν χρειάζεται να συμπληρώσετε κάτι).  Τέλος θα ήταν βοηθητικό να έχουμε και μια μέθοδο η όποια θα μετατρέπει την κατανομή εξόδου στην επιστρεφόμενη κλάση (predict) για κάποιο ή κάποια στιγμιότυπα του συνόλου δεδομένων.   \n",
        "\n",
        "Το δίκτυο όπως αναφέρθηκε και προηγουμένως αποτελείται από έναν αριθμό Dense επιπέδων κάθε ένα από τα όποια ακολουθείται από μια συνάρτηση ReLU. Η κατασκευή των επιπέδων γίνεται κατά την στιγμή δημιουργίας του δικτύου, όπου δίνεται ως είσοδος μια λίστα με το μέγεθος κάθε επιπέδου, μαζί με το μέγεθος εισόδου. Έτσι για παράδειγμα η παρακάτω γραμμή κώδικα:  \n",
        "``` \n",
        "net = MLP([100, 200, 100, 10], 784)  \n",
        "```  \n",
        "κατασκευάζει ένα MLP το όποιο αποτελείται από 4 επίπεδα με μέγεθος 100, 200, 100, 10. Ο αριθμός των επιπέδων καθώς και του μεγέθους καθενός από αυτά είναι ελεύθερος να οριστεί από τον χρήστη.   \n",
        "Στον constructor της κλάσης ουσιαστικά ορίζεται μια λίστα η όποια περιέχει κάθε ένα από τα επίπεδα που πρέπει να οριστούν, π.χ. για το παραπάνω παράδειγμα η μεταβλητή net.network περιέχει τα εξής στιγμιότυπα των κλάσεων:  \n",
        "\n",
        "``` \n",
        "[Dense(100), ReLU(), Dense(200), ReLU(), Dense(100), ReLU(), Dense(10)]  \n",
        "```  \n",
        "\n",
        "Συνεπώς η λειτουργικότητα του δικτύου όπως και πριν πρέπει να οριστεί στην μέθοδο forward. Στο σημείο αυτό καλείστε να συμπληρώσετε την μέθοδο αυτή έτσι ώστε το δίκτυο να λειτουργεί όπως πρέπει, δηλαδή στο παράδειγμά μας η είσοδος να περνά από το επίπεδο Dense(100), μετά από το ReLU(), στην συνέχεια από το Dense(200) κ.ο.κ. μέχρι και το τελευταίο επίπεδο.  Ο αλγόριθμος αυτός παρουσιάζεται και σε ψευδοκώδικα στην διαφάνεια 33 του μαθήματος. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHHcg1unbf21"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    def __init__(self, shapes, input_dim):\n",
        "        self.shapes = shapes\n",
        "        self.network = [Dense(input_dim, shapes[0])]\n",
        "        self.network.append(ReLU())\n",
        "        for i in range(1, len(self.shapes) - 1):\n",
        "            self.network.append(Dense(shapes[i-1], shapes[i]))\n",
        "            self.network.append(ReLU())\n",
        "        self.network.append(Dense(shapes[i], shapes[-1]))\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Αγόριθμος διφάνειας 33\n",
        "        \"\"\"\n",
        "        activations = []\n",
        "        input = X\n",
        "        # Looping through each layer\n",
        "        for l in self.network:\n",
        "            ###################\n",
        "            ## Your code below\n",
        "            # hint: τροφοδοτούμε την έξοδο κάθε επιπέδου στο επόμενο\n",
        "            \n",
        "            pass\n",
        "\n",
        "            ## Your code above\n",
        "            ##################        \n",
        "        assert len(activations) == len(self.network)\n",
        "        return activations\n",
        "\n",
        "    def predict(self,X):\n",
        "        \"\"\"\n",
        "        Προβλέπει την έξοδο του δικτύου για ένα ή περισσότερα στιγμιότυπα εισόδου\n",
        "        \"\"\"\n",
        "        logits = self.forward(X)[-1]\n",
        "        return logits.argmax(axis = -1)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Get the layer activations\n",
        "        layer_activations = self.forward(X)\n",
        "        layer_inputs = [X]+layer_activations \n",
        "        logits = layer_activations[-1]\n",
        "\n",
        "        # Compute the loss and the initial gradient\n",
        "        loss = softmax_crossentropy_with_logits(logits,y)\n",
        "        loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
        "\n",
        "        # Propagate gradients through the network\n",
        "        # Reverse propogation as this is backprop\n",
        "        for layer_index in range(len(self.network))[::-1]:\n",
        "            layer = self.network[layer_index]\n",
        "            loss_grad = layer.backward(layer_inputs[layer_index],loss_grad) \n",
        "        return np.mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zCBcKqvbm4t"
      },
      "source": [
        "## Αξιολόγηση ενός Multi-Layer Perceptron\n",
        "\n",
        "Αφού έχουμε κατασκευάσει τα παραπάνω είμαστε πλέον σε θέση να εκπαιδεύσουμε το MLP. Αυτό γίνεται καλώντας την μέθοδο fit. Στο παρακάτω κελί κώδικα ορίζεται το MLP του παραπάνω παραδείγματος και εκπαιδεύεται για 25 εποχές. Στο τέλος κάθε εποχής παρουσιάζονται τα αποτελέσματα του μαζί με μια γραφική των train και test accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jw-8qN6bjQG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "\n",
        "network = MLP([10, 15, 20, 3], len(inputs))\n",
        "\n",
        "train_log = []\n",
        "val_log = []\n",
        "\n",
        "for epoch in range(25):\n",
        "    network.fit(x_train, y_train)   \n",
        "    train_log.append(np.mean(network.predict(x_train) == y_train))\n",
        "    val_log.append(np.mean(network.predict(x_test) == y_test))\n",
        "    #clear_output()\n",
        "    print(\"Epoch\", epoch)\n",
        "    print(\"Train accuracy:\", train_log[-1])\n",
        "    print(\"Val accuracy:\", val_log[-1])  \n",
        "    plt.plot(train_log,label = 'train accuracy')\n",
        "    plt.plot(val_log,label = 'val accuracy')\n",
        "    plt.legend(loc = 'best')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "y_pred = network.predict(x_test)\n",
        "\n",
        "eval = Evaluate(y_test, y_pred)\n",
        "eval.get_evaluation_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygud3NX3b-wN"
      },
      "source": [
        "## Έτοιμο Multi-Layer Perceptron \n",
        "\n",
        "Όπως και με τις τεχνικές των παραπάνω ερωτημάτων έτσι και εδώ υπάρχει έτοιμη η παραπάνω κλάση σε διάφορες βιβλιοθήκες. Έτσι στο δεύτερο μέρος του ερωτήματος αυτού θα κατασκευάσετε το ίδιο MLP χρησιμοποιώντας όμως την έτοιμη κλάση [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)  της βιβλιοθήκης scikit-learn. Παρακάτω παρουσιάζεται ένα παράδειγμα χρήσης της κλάσης αυτής. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hltXBE2Vbojo"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "epochs = 25\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 15, 20), max_iter = epochs)\n",
        "\n",
        "mlp.fit(x_train,y_train)\n",
        "\n",
        "y_pred = mlp.predict(x_test)\n",
        "eval = Evaluate(y_test, y_pred)\n",
        "eval.get_evaluation_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOQYML9wcDBk"
      },
      "source": [
        "## Σύγκριση υλοποιήσεων \n",
        "\n",
        "  \n",
        "\n",
        "Στα παρακάτω κελιά πειραματιστείτε με τις δύο υλοποιήσεις (τη δική σας και την έτοιμη). Συγκρίνετε τα αποτελέσματά σας τόσο ως προς τους χρόνους εκτέλεσης αλλά και ως προς τα αποτελέσματα. Η διαφορά των αποτελεσμάτων προκύπτει από το ότι στην έτοιμη κλάση έχουν γίνει αρκετές βελτιστοποιήσεις στην λειτουργία, στον τρόπο εκπαίδευσης κ.α. με αποτέλεσμα να προκύπτουν καλύτερα αποτέλεσματα. Παρόλα αυτά στην δική μας κλάση έχουμε καλύτερο έλεγχο και έχουμε την δυνατότητα να σχεδιάσουμε πιο σύνθετες αρχιτεκτονικές καθώς να αλλάξουμε τις τιμές παραμέτρων που στην έτοιμη κλάση μπορεί να μην μας δίνεται η δυνατότητα. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfrx064gcCr8"
      },
      "source": [
        "# Αξιολόγηση- Συμπεράσματα \n",
        "\n",
        "  \n",
        "\n",
        "Τέλος στο σημείο αυτό καλείστε να αξιολογήσετε τις διάφορες τεχνικές ταξινόμησης (KNN, Naive Bayes, MLP), τα αποτελέσματά τους, τους χρόνους εκτέλεσης, και να παραθέσετε παρατηρήσεις καθώς και οτιδήποτε σας φάνηκε ενδιαφέρον ή ιδιαίτερο. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Απάντηση/Σχολιασμός:"
      ],
      "metadata": {
        "id": "mg-H_2wECiP5"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3rd_lab_assignment_AI (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}